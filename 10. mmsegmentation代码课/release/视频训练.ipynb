{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Roger\\\\Desktop\\\\OpenMMLabCourseStudy\\\\10.mmsegmentation代码课\\\\release\\\\mmsegmentation'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "os.chdir('mmsegmentation')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python demo/video_demo.py \\\n",
    "        data/street_20220330_174028.mp4 \\\n",
    "        configs/mask2former/mask2former_swin-l-in22k-384x384-pre_8xb2-90k_cityscapes-512x1024.py \\\n",
    "        https://download.openmmlab.com/mmsegmentation/v0.5/mask2former/mask2former_swin-l-in22k-384x384-pre_8xb2-90k_cityscapes-512x1024/mask2former_swin-l-in22k-384x384-pre_8xb2-90k_cityscapes-512x1024_20221202_141901-28ad20f1.pth \\\n",
    "        --device cuda:0 \\\n",
    "        --output-file outputs/B3_video.mp4 \\\n",
    "        --opacity 0.5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "import mmcv\n",
    "import mmengine\n",
    "from mmseg.apis import inference_model\n",
    "from mmseg.utils import register_all_modules\n",
    "register_all_modules()\n",
    "\n",
    "from mmseg.datasets import CityscapesDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型 config 配置文件\n",
    "config_file = 'configs/mask2former/mask2former_swin-l-in22k-384x384-pre_8xb2-90k_cityscapes-512x1024.py'\n",
    "\n",
    "# 模型 checkpoint 权重文件\n",
    "checkpoint_file = 'https://download.openmmlab.com/mmsegmentation/v0.5/mask2former/mask2former_swin-l-in22k-384x384-pre_8xb2-90k_cityscapes-512x1024/mask2former_swin-l-in22k-384x384-pre_8xb2-90k_cityscapes-512x1024_20221202_141901-28ad20f1.pth'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmsegmentation/v0.5/mask2former/mask2former_swin-l-in22k-384x384-pre_8xb2-90k_cityscapes-512x1024/mask2former_swin-l-in22k-384x384-pre_8xb2-90k_cityscapes-512x1024_20221202_141901-28ad20f1.pth\n"
     ]
    }
   ],
   "source": [
    "from mmseg.apis import init_model\n",
    "model = init_model(config_file, checkpoint_file, device='cuda:0')\n",
    "\n",
    "from mmengine.model.utils import revert_sync_batchnorm\n",
    "if not torch.cuda.is_available():\n",
    "    model = revert_sync_batchnorm(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "input_video = 'data/street_20220330_174028.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "创建临时文件夹 20230614220803 用于存放每帧预测结果\n"
     ]
    }
   ],
   "source": [
    "temp_out_dir = time.strftime('%Y%m%d%H%M%S')\n",
    "os.mkdir(temp_out_dir)\n",
    "print('创建临时文件夹 {} 用于存放每帧预测结果'.format(temp_out_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取 Cityscapes 街景数据集 类别名和调色板\n",
    "from mmseg.datasets import cityscapes\n",
    "classes = cityscapes.CityscapesDataset.METAINFO['classes']\n",
    "palette = cityscapes.CityscapesDataset.METAINFO['palette']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pridict_single_frame(img, opacity=0.2):\n",
    "    \n",
    "    result = inference_model(model, img)\n",
    "    \n",
    "    # 将分割图按调色板染色\n",
    "    seg_map = np.array(result.pred_sem_seg.data[0].detach().cpu().numpy()).astype('uint8')\n",
    "    seg_img = Image.fromarray(seg_map).convert('P')\n",
    "    seg_img.putpalette(np.array(palette, dtype=np.uint8))\n",
    "    \n",
    "    show_img = (np.array(seg_img.convert('RGB')))*(1-opacity) + img*opacity\n",
    "    \n",
    "    return show_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                                                  ] 0/159, elapsed: 0s, ETA:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Roger\\anaconda3\\envs\\mmlab\\lib\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\TensorShape.cpp:3484.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 138/138, 43.9 task/s, elapsed: 3s, ETA:     0s[                                                  ] 0/138, elapsed: 0s, ETA:\n",
      "删除临时文件夹 20230614220803\n"
     ]
    }
   ],
   "source": [
    "# 读入待预测视频\n",
    "imgs = mmcv.VideoReader(input_video)\n",
    "\n",
    "prog_bar = mmengine.ProgressBar(len(imgs))\n",
    "\n",
    "# 对视频逐帧处理\n",
    "for frame_id, img in enumerate(imgs):\n",
    "    \n",
    "    ## 处理单帧画面\n",
    "    show_img = pridict_single_frame(img, opacity=0.15)\n",
    "    temp_path = f'{temp_out_dir}/{frame_id:06d}.jpg' # 保存语义分割预测结果图像至临时文件夹\n",
    "    cv2.imwrite(temp_path, show_img)\n",
    "\n",
    "    prog_bar.update() # 更新进度条\n",
    "\n",
    "# 把每一帧串成视频文件\n",
    "mmcv.frames2video(temp_out_dir, 'outputs/B3_video.mp4', fps=imgs.fps, fourcc='mp4v')\n",
    "\n",
    "shutil.rmtree(temp_out_dir) # 删除存放每帧画面的临时文件夹\n",
    "print('删除临时文件夹', temp_out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
